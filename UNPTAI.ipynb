{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvm:7: command not found: tr\n",
      "nvm:7: command not found: tr\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/jack/anaconda3/lib/python3.11/site-packages/mecab_python-0.996-py3.11-macosx-11.1-arm64.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /Users/jack/anaconda3/lib/python3.11/site-packages (1.30.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/jack/anaconda3/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jack/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: certifi in /Users/jack/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore in /Users/jack/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/jack/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/jack/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jack/anaconda3/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key  = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 27\u001b[0m\n\u001b[1;32m     10\u001b[0m userProfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m은(는) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserAge\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m살이고, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserGender\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m이며, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserMajor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m을(를) 전공하고 있습니다. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserHobby\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m을(를) 좋아하며, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muserCity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m에 있는 대학을 찾고 있습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     13\u001b[0m     {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     },\n\u001b[1;32m     25\u001b[0m ]\n\u001b[0;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,    \n\u001b[1;32m     29\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m     30\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     32\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     33\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     34\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "model='gpt-3.5-turbo'\n",
    "\n",
    "userName = \"김철수\"\n",
    "userAge = \"20\"\n",
    "userGender = \"남성\"\n",
    "userMajor = \"컴퓨터공학\"\n",
    "userHobby = \"영화감상\"\n",
    "userCity = \"서울\"\n",
    "\n",
    "userProfile = f\"{userName}은(는) {userAge}살이고, {userGender}이며, {userMajor}을(를) 전공하고 있습니다. {userHobby}을(를) 좋아하며, {userCity}에 있는 대학을 찾고 있습니다.\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":\n",
    "        {\n",
    "            \"text\": \"University Classification Prompt:\\n\\n\\n\\nBased on the provided university data, provide leisure, weather, location, and major information for the city where each university is located. Follow these criteria to classify each category:\\n\\n\\n\\nLeisure activities:\\n\\n\\n\\n- Classify as \\\"Extroverted (E)\\\" if the city mainly features active facilities such as amusement parks, landmarks, cafes, bars, sports stadiums, etc.\\n\\n- Classify as \\\"Introverted (I)\\\" if the city mainly features calm facilities such as libraries, cinemas, bookstores, etc.\\n\\n\\n\\nWeather:\\n\\n\\n\\n- Classify as \\\"Sunny (S)\\\" if the city generally has warm weather with temperatures frequently above 15°C.\\n\\n- Classify as \\\"Freeze (F)\\\" if the city generally has cold weather with temperatures frequently below 15°C.\\n\\n\\n\\nLocation:\\n\\n\\n\\n- Classify as \\\"City (C)\\\" if the city's population exceeds 100,000.\\n\\n- Classify as \\\"Town (T)\\\" if the city's population is 100,000 or less.\\n\\n\\n\\nMajor:\\n\\n\\n\\n- Classify as \\\"Liberal arts (L)\\\" if the university is known for liberal arts, humanities, or business.\\n\\n- Classify as \\\"Nature (N)\\\" if the university is known for science, technology, engineering, or mathematics.\\n\\n\\n\\nEnsure each university is classified with exactly one option for each category (E/I, S/F, C/T, L/N).\\n\\n\\n\\nResponse format:\\n\\n대학: [University Name]\\n\\nUNPT: [E | I][S | F][C | T][L | N]\\n\\n여가정보: [Extroverted | Introverted]\\n\\n지리정보: [Sunny | Freeze]\\n\\n지역정보: [City | Town]\\n\\n전공정보: [Liberal arts | Nature]\\n\\n도시: [City Name]\\n\\n추천 시설: [Recommended Facility 1], [Recommended Facility 2], [Recommended Facility 3]\\n\\n\\n\\nInitial Question Generation:\\n\\n\\n\\nBased on the provided criteria, generate an initial open-ended question in Korean to classify the user's preferences. \\nIt doesn't give you any options to choose from.\\nquestion is very creativity and diversity. Continue asking up to three open-ended questions based on the user's responses. After receiving the responses, classify the UNPT and recommend three universities that match the determined UNPT.\\nPlease return only questions\\n\\n\\n\\nEnd of prompt.\",\n",
    "            \"type\": \"text\"\n",
    "        }  \n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"이 유저의 프로필 데이터와 유사한 대학을 추천해주면 돼\" + userProfile\n",
    "    },\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model,    \n",
    "    messages=messages,\n",
    "    temperature=1,\n",
    "    max_tokens=1000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
